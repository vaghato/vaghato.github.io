<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Evangelos Chatzipantazis</title>

    <meta name="author" content="Evangelos Chatzipantazis">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <script src="https://kit.fontawesome.com/57404b6a96.js" crossorigin="anonymous"></script>
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Evangelos Chatzipantazis
                </p>
                <p>Hello visitor! I am Evangelos. My name stems from the Greek Ev (< εύ) + angelos (< ἄγγελος) which translates to "the messenger of good news". So yes; if you are looking for good news you are in the right place.<br><br>
                   I am currently a PhD Student in Computer Science at the legendary <a href="https://www.grasp.upenn.edu/"> Grasp Lab</a> at the <a href="https://www.upenn.edu/">University of Pennsylvania</a>.
                   Under the advising of <a href="https://www.cis.upenn.edu/~kostas/">Kostas Daniilidis</a>, I work on Geometric Deep Learning and its applications to 3D Computer Vision and Robotics. <br><br>

                   Moreover, I am currently doing an internship at <a href="https://theaiinstitute.com/">Boston Dynamics AI Institute</a> under <a href="https://www.khoury.northeastern.edu/people/robert-platt/">Prof. Robert Platt</a> and <a href="https://www.robinwalters.com/">Prof. Robin Walters</a>
                   where I work on policy learning for robot manipulation.
                </p>
                <p>
                  I hold a Master of Science in Robotics from UPenn and a Master of Science in Statistics and Data Science from Wharton.  
                  Prior to that, I completed my undergraduate studies in the field of Electrical Engineering and Computer Science at the 
                  <a href="https://www.ntua.gr/en/">National Technical University of Athens</a>, under the supervision of Prof. 
                  <a href="http://cvsp.cs.ntua.gr/maragos/index.shtm">Petros Maragos</a>, 
                  where I conducted research on spectral methods for image segmentation.
                </p>
                <p style="text-align:center">
                  <a href="mailto:vaghat@seas.upenn.edu">
                    <span class="fa-stack fa-lg">
                      <i class="fa-solid fa-envelope"></i>
                    </span>
                  </a>
                  <a href="data/EvangelosChatzipantazis_Resume.pdf"> 
                    <span class="fa-stack fa-lg">
                      <i class="fa-solid fa fa-file"></i>
                    </span> </a>  
                  <a href="https://scholar.google.com/citations?user=qQsYhTgAAAAJ&hl=en">
                    <span class="fa-stack fa-lg">
                      <i class="fa-brands fa-google-scholar"></i>
                      </span>
                  </a> 
                  <a href="https://twitter.com/EChatzipantazis"> 
                    <span class="fa-stack fa-lg">
                    <i class="fa fa-twitter fa-stack-1x"></i>
                    </span> </a> 
                  <a href="https://github.com/vaghato">
                    <span class="fa-stack fa-lg">
                      <i class="fa-brands fa-github"></i>
                    </span> </a> 
                  <a href="https://www.linkedin.com/in/evangelos-chatzipantazis-b43b132a2">
                    <span class="fa-stack fa-lg">
                      <i class="fa-brands fa-linkedin-in"></i>
                    </span>
                  </a> 
                </p>
                

              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/EvChatz.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/EvChatz_circle.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My current research focus lies on <a href="https://youtu.be/bmEpQDLxdoI?t=18259">Equivariant Deep Learning</a> for 3D Computer Vision and Robotics. 
                  More broadly, I am interested in problems that fuse geometry, statistics and physics especially in the form of inductive biases on deep neural networks.
                  I am also very interested in the use of <a href="https://ai4sciencecommunity.github.io/">Artificial Intelligence for Science</a>. <br><br>

                  During my PhD I have worked on 3D perception tasks, mainly on 3d reconstruction and point cloud registration. <br>
                  On the theory side, I have designed frameworks to learn symmetries from data as well as optimization frameworks for equivariant deep networks. <br><br>

                  I have collaborated on a project on system identification that received the <a href="https://www.linkedin.com/posts/charis-stamouli-20b35b200_acc2024-activity-7221130706104549377-X8uw?utm_source=share&utm_medium=member_desktop">Best Student Paper Award in ACC 2024</a> and
                  on a project on graph neural networks for active information acquisition that received the <a href="https://www.ieee-ras.org/awards-recognition/conference-awards/ieee-icra-best-paper-award-on-multi-robot-systems-sponsored-by-amazon-robotics">Best Paper Award in ICRA 2023 in the category of multi-robot systems</a>
                  sponsored by Amazon Robotics.
                  
                </p>
              </td>
            </tr>
          </tbody></table>



          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
            <tr onmouseout="eqcr_stop()" onmouseover="eqcr_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='eqcr_image'>
                    <img src='images/ApproximateEquivariance.png' width="160" height="125"></div>
                  <img src='images/ApproximateEquivariance.png' width="160" height="125">
                </div>
                <script type="text/javascript">
                  function trm_start() {
                    document.getElementById('eqcr_image').style.opacity = "1";
                  }
            
                  function trm_stop() {
                    document.getElementById('eqcr_image').style.opacity = "0";
                  }
                  trm_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2408.13242">
                  <span class="papertitle">Improving Equivariant Model Training via Constraint Relaxation
            </span>
                </a>
                <br>
                <strong>Stefanos Pertigkiozoglou*</strong>,
                <a href="https://vaghato.github.io/">Evangelos Chatzipantazis*</a>,
                <a href="https://home.ttic.edu/~shubhendu/">Shubhendu Trivedi</a>,
                <a href="https://www.cis.upenn.edu/~kostas/">Kostas Daniilidis</a>,
                <br>
              <em>Advances in Neural Information Processing Systems (NeurIPS)<em>, 2024, <a href="https://arxiv.org/pdf/2408.13242">pdf</a>
                <br>
                <p></p>
                <p>
                  Introduced a novel method for improving the training of Equivariant Neural Networks. Specifically, we showcased how relaxing
                  the equivariant constraint during training and projecting back to the space of equivariant models during inference can improve
                  the overall optimization
                </p>
              </td>
            </tr>    

            <tr onmouseout="bieq_stop()" onmouseover="bieq_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='bieq_image'>
                    <img src='images/BiEquivariantRegistration.jpg' width="160" ></div>
                  <img src='images/BiEquivariantRegistration.jpg' width="160" >
                </div>
                <script type="text/javascript">
                  function trm_start() {
                    document.getElementById('bieq_image').style.opacity = "1";
                  }
            
                  function trm_stop() {
                    document.getElementById('bieq_image').style.opacity = "0";
                  }
                  trm_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2407.08729">
                  <span class="papertitle">BiEquiFormer: Bi-Equivariant Representations for Global Point Cloud Registration
            </span>
                </a>
                <br>
                <strong>Stefanos Pertigkiozoglou*</strong>,
                <a href="https://vaghato.github.io/">Evangelos Chatzipantazis*</a>,
                <a href="https://www.cis.upenn.edu/~kostas/">Kostas Daniilidis</a>,
                <br>
              <em>Symmetry and Geometry in Neural Representations Workshop (NeurReps)<em>, 2024, <a href="https://arxiv.org/pdf/2407.08729">pdf</a>
                <br>
                <p></p>
                <p>
                  Proposed a novel point cloud registration method that utilizes bi-equivariant representations to achieve robust point cloud
                  alignment, that is independent of the initial poses of the input point clouds.
                </p>
              </td>
            </tr>


            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/eqnio.png' width="200" height="150">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2408.06321">
                  <span class="papertitle">EqNIO: Subequivariant Neural Inertial Odometry</span>
                </a>
                <br>
                <a href=https://scholar.google.com/citations?user=37Eq28IAAAAJ&hl=en>Royina Karegoudra Jayanth*</a>,
                <a href=https://www.cis.upenn.edu/~xuyin/>Yinshuang Xu*</a>,
                <a href=https://ziyunclaudewang.github.io/>Ziyun Wang</a>,
                <strong>Evangelos Chatzipantazis</strong>,
                <a href=https://danielgehrig18.github.io/>Daniel Gehrig</a>,
                <a href="https://www.cis.upenn.edu/~kostas/">Kostas Daniilidis</a>
                <br>
                <em>Under Review</em>, 2024
                <br>
                <a href="https://arxiv.org/abs/2408.06321">arXiv</a> / 
                <a href="https://drive.google.com/file/d/1o0XuYGGke1g2xwA2XFo5vD_K5_c5U71x/view?usp=sharing">slides</a>
                <p>
                  Neural networks are seeing rapid adoption in purely inertial odometry, where accelerometer and gyroscope measurements 
                  from commodity inertial measurement units (IMU) are used to regress displacements and associated uncertainties. 
                  They can learn informative displacement priors, which can be directly fused with the raw data with off-the-shelf 
                  non-linear filters. Nevertheless, these networks do not consider the physical roto-reflective symmetries inherent in 
                  IMU data, leading to the need to memorize the same priors for every possible motion direction, which hinders generalization. 
                  In this work, we characterize these symmetries and show that the IMU data and the resulting displacement and covariance 
                  transform equivariantly, when rotated around the gravity vector and reflected with respect to arbitrary planes 
                  parallel to gravity. We design a neural network that respects these symmetries by design through equivariant processing 
                  in three steps: First, it estimates an equivariant gravity-aligned frame from equivariant vectors and invariant scalars derived 
                  from IMU data, leveraging expressive linear and non-linear layers tailored to commute with the underlying symmetry 
                  transformation. We then map the IMU data into this frame, thereby achieving an invariant canonicalization that can be 
                  directly used with off-the-shelf inertial odometry networks. Finally, we map these network outputs back into the original 
                  frame, thereby obtaining equivariant covariances and displacements. We demonstrate the generality of our framework by 
                  applying it to the filter-based approach based on TLIO, and the end-to-end RONIN architecture, and show better performance 
                  on the TLIO, Aria, RIDI and OxIOD datasets than existing methods.
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/charis.png' width="200" height="175">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10644471">
                  <span class="papertitle">Structural Risk Minimization for Learning Nonlinear Dynamics</span>
                </a>
                <br>
                <a href=https://charis-stamouli.github.io/>Charis Stamouli</a>,
                <strong>Evangelos Chatzipantazis</strong>,
                <a href="https://www.georgejpappas.org/">George Pappas</a>
                <br>
                <em>American Control Conference ACC</em>, 2024
                <br>
                <font color="red"><strong>(Best Student Paper Award)</strong></font>
                <br>
                <a href="https://arxiv.org/abs/2309.16527">arXiv</a> / 
                <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10644471">proceedings</a> /
                <a href="https://drive.google.com/file/d/1s5i2JSPaQC0Ugjq2ADARsO8mwVRUzaou/view?usp=sharing">slides</a>
                <p>
                  Recent advances in learning or identification of nonlinear dynamics focus on learning a suitable model 
                  within a pre-specified model class. However, a key difficulty that remains is the choice of the model class from 
                  which the dynamics will be learned. The fundamental challenge is trading the richness of the model class with the 
                  learnability within the model class. Toward addressing the so-called model selection problem, we introduce a novel 
                  notion of Structural Risk Minimization (SRM) for learning nonlinear dynamics. Inspired by classical SRM for classification, 
                  we minimize a bound on the true prediction error over hierarchies of model classes. The class selected by our SRM scheme is 
                  shown to achieve a nearly optimal learning guarantee among all model classes contained in the hierarchy. 
                  Employing the proposed scheme along with computable model class complexity bounds, we derive explicit SRM schemes 
                  for learning nonlinear dynamics under hierarchies of: i) norm-constrained Reproducing Kernel Hilbert Spaces, and 
                  ii) norm-constrained Neural Network classes. We empirically show that even though too loose to be used as absolute 
                  estimates, our SRM bounds on the true prediction error are able to track its relative behavior across different 
                  model classes of the hierarchy.
                </p>
              </td>
            </tr>
            
            
            <tr onmouseout="se3video_stop()" onmouseover="se3video_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='TFONet_types'><video  width="180" height="140" muted autoplay loop>
                  <source src="images/TFONet_teaser.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/TFONet_types.png' width="180" height="140">
                </div>
                <script type="text/javascript">
                  function se3video_start() {
                    document.getElementById('TFONet_types').style.opacity = "1";
                  }
      
                  function se3video_stop() {
                    document.getElementById('TFONet_types').style.opacity = "0";
                  }
                  se3video_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://openreview.net/forum?id=RDy3IbvjMqT">
                  <span class="papertitle">SE(3)-Equivariant Attention Networks for Shape Reconstruction in Function Space </span>
                </a>
                <br>
                <strong>Evangelos Chatzipantazis</strong>*,
                <a href=https://scholar.google.com/citations?user=kMTVEZYAAAAJ&hl=el&oi=ao>Stefanos Pertigkiozoglou*</a>,
                <a href="https://statistics.wharton.upenn.edu/profile/dobriban/">Edgar Dobriban</a>,
                <a href="https://www.cis.upenn.edu/~kostas/">Kostas Daniilidis</a>
                <br>
                <em>The Eleventh International Conference on Learning Representations ICLR</em>, 2023
                <br>
                <a href="https://sites.google.com/seas.upenn.edu/tfonet">project page</a>
                /
                <a href="https://docs.google.com/presentation/d/12Vyh7kOIWpx6J6HuUlcix1I89ObP-LVAL0tZKUUwf6s/edit#slide=id.g116809db50c_0_177">slides</a>
                /
                <a href="https://arxiv.org/abs/2204.02394">arXiv</a> /
                <a href="https://openreview.net/forum?id=RDy3IbvjMqT">openreview</a>
                <p>
                Local shape modeling and SE(3)-equivariance are strong inductive biases to reconstruct scenes of arbitrarily many objects appearing in random poses even when a network is trained on single objects in canonical pose. 
                </p>
              </td>
            </tr>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/fixedPDF_withReg2-1.png' width="220" height="90">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://openreview.net/forum?id=LRYtNj8Xw0">
                  <span class="papertitle">Learning Augmentation Distributions using Transformed Risk Minimization</span>
                </a>
                <br>
                <strong>Evangelos Chatzipantazis</strong>*,
                <a href=https://scholar.google.com/citations?user=kMTVEZYAAAAJ&hl=el&oi=ao>Stefanos Pertigkiozoglou*</a>,
                <a href="https://www.cis.upenn.edu/~kostas/">Kostas Daniilidis</a>,
                <a href="https://statistics.wharton.upenn.edu/profile/dobriban/">Edgar Dobriban</a>,
                <br>
                <em>Transactions on Machine Learning Research TMLR</em>, 2023
                <br>
                <a href="https://arxiv.org/pdf/2111.08190.pdf">arXiv</a> / 
                <a href="https://openreview.net/forum?id=LRYtNj8Xw0">openreview</a>
                <p>
                  We propose a new Transformed Risk Minimization (TRM) framework as an 
                  extension of classical risk minimization. 
                  Our TRM method (1) jointly learns transformations and models in a single training loop,
                  (2) works with any training algorithm applicable to standard risk minimization, 
                  and (3)  handles any transforms, such as discrete and continuous classes of augmentations.
                  To avoid overfitting when implementing empirical transformed risk minimization, 
                  we propose a novel regularizer based on PAC-Bayes theory. 
                  We propose a new parametrization of the space of augmentations via a stochastic composition of blocks 
                  of geometric transforms. The performance compares favorably to prior methods on CIFAR10/100. 
                  Additionally, we show empirically that we can correctly learn certain symmetries in the data distribution
                  (recovering rotations on rotated MNIST) and can also improve calibration of the learned model.
                </p>
              </td>
            </tr>

            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
              <div class="two" id='gnns4aia_image'>
                <img src='images/gnns4aia.png' width=100%>
              </div>
              <script type="text/javascript">
              </script>
            <!--<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/gnns4aia.png" alt="gnns4aia" width="160" height="160">
            </td>-->
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/seas.upenn.edu/gnn4aia/home">
              <span class="papertitle">Graph Neural Networks for Multi-Robot Active Information Acquisition</span>
              </a>
              <br>
              <a href=https://mtzes.github.io>Mariliza Tzes</a>, Nikolaos Bousias, <strong>Evangelos Chatzipantazis</strong>, <a href="https://www.georgejpappas.org/">George J. Pappas</a>
              <br>
              <em>IEEE International Conference on Robotics and Automation, ICRA</em>, 2023
              <br>
              <font color="red"><strong>(Outstanding Paper Award in Multi-Robot Systems)</strong></font>
              <br>
              <a href="https://sites.google.com/seas.upenn.edu/gnn4aia/home">project page</a>
              /
              <a href="https://www.youtube.com/watch?v=pQGiRfijGEs">video</a>
              /
              <a href="https://ieeexplore.ieee.org/document/10160723">paper</a>
              /
              <a href="https://arxiv.org/abs/2209.12091">arxiv</a>
              <p></p>
              <p>We propose the Information-aware Graph Block Network (I-GBNet), an Active Information Acquisition adaptation of Graph Neural Networks, that aggregates information over the graph representation and provides sequential-decision making in a distributed manner. Numerical simulations on significantly larger graphs and dimensionality of the hidden state and more complex environments than those seen in training validate the properties of the proposed architecture and its efficacy in the application of localization and tracking of dynamic targets.</p>
            </td>
          </td>            
          </tbody></table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Talks</h2>
                <p></p>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>


            <tr>
              <td style="padding-bottom:70px;padding-left:15px; padding-right:105px;width:25%;">
                <div class="one">
                  <img src='images/tutorial.png' width="266" height="150">
                </div>
              </td>
              <td style="padding-top:0px;width:75%;">
                <a href="https://equivision.github.io/">
                  <span class="papertitle">Invited Speaker in CVPR 2024 workshop on Equivariant Vision: From Theory to Practice.</span>
                </a>
                <p>
                  <a href="https://youtu.be/bmEpQDLxdoI?t=18259">Tutorial: ”How to get started with equivariant deep learning”</a><br>
                  <ul>
                    <li><a href="https://youtu.be/bmEpQDLxdoI?t=18259">Video <i class="fa-solid fa-video"></i></a></li>
                    <li><a href="https://docs.google.com/presentation/d/18WvpLnCNtwSSdbWdqmOvuDq1lnXX2dfaDMlpYIgB2Tk/edit?usp=sharing">Slides <i class="fa fa-file-powerpoint-o"></i></a></li>
                  </ul>
                </p>
              </td>
            </tr>

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
              <tr>
                <td>
                  <h2>Organizer</h2>
                  <p></p>
                </td>
              </tr>
            </tbody></table>
            <table width="100%" align="center" border="0" cellpadding="20"><tbody>
  
              <tr>
                <td style="padding-bottom:70px;padding-left:15px; padding-right:105px;width:25%;">
                  <div class="one">
                    <img src='images/equirob.jpg' width="260" height="180">
                  </div>
                </td>
                <td style="padding-top:0px;width:75%;">
                  <a href="https://equirob2024.github.io/">
                  <span class="papertitle">Organizer in IROS 2024 Workshop:
                      <p>Equivariant Robotics:
                      The Role of Symmetry Across Perception, Estimation, and Control.
                    </p>
                  </span>
                  </a>
                  <p>
                    <a href="https://www.youtube.com/watch?v=-G7TFaro-v8&list=PLhUS2I3r0CrNusEns2A1zNwPX3xfe7WGi&t=2s">Recording <i class="fa-solid fa-video"></i> </a><br>
                  </p>
                </td>
              </tr>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Teaching</h2>
                <p>I am very passionate about teaching. Both from the mentoring perspective and as a means to convey knowledge in a clear, concise manner. I am a big fan of <a href="https://www.youtube.com/watch?v=EyssfKRsgMU">Richard Feynman's teaching techniques.</p>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>


            <tr>
              <td style="padding-bottom:80px;padding-left:15px;width:25%;">
                <div class="one">
                  <img src='images/ESE546.png' width="200" height="250">
                </div>
              </td>
              <td style="padding-top:50px;width:75%;">
                <a href="https://pratikac.github.io/pub/20_ese546.pdf">
                  <span class="papertitle">Teaching Assistant, ESE546 Principles of Deep Learning Fall 2019, 2020 </span>
                </a>
                <p>
                  <a href="https://pratikac.github.io/pub/20_ese546.pdf">Class Notes</a> (Co-authored with Prof.<a href="https://pratikac.github.io/">Pratik Chaudhari</a>)
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding-top:20px;padding-left:65px; width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/CIS680.png' width="100" height="120">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://sites.google.com/seas.upenn.edu/cis680fall19">
                  <span class="papertitle">Teaching Assistant, CIS680 Advanced Machine Perception, Fall 2019  </span>
                </a>
                <p>
                  <a href="https://sites.google.com/seas.upenn.edu/cis680fall19/home?authuser=0">Website</a> (under Prof. <a href="https://www.cis.upenn.edu/~jshi/">Jianbo Shi</a>)
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
              </td>
              <td width="75%" valign="center">
                Teaching Assistant, ESE650 Learning in Robotics, Spring 2019 under Prof. <a href="https://www.cis.upenn.edu/~kostas/">Kostas Daniilidis</a>. 
              </td>
            </tr>


                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                      <tr>
                        <td style="padding:0px">
                          <br>
                          <p style="text-align:right;font-size:small;">
                            Credits for the template <a href="https://jonbarron.info/">Jon Barron</a>
                          </p>
                        </td>
                      </tr>
                    </tbody></table>
                  </td>
                </tr>
              </table>



  </body>
</html>
